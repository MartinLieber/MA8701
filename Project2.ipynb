{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T14:48:55.533145Z",
     "iopub.status.busy": "2021-02-09T14:48:55.532569Z",
     "iopub.status.idle": "2021-02-09T14:48:56.354332Z",
     "shell.execute_reply": "2021-02-09T14:48:56.353423Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import linear_model\n",
    "import seaborn as sns\n",
    "import datetime\n",
    "from group_lasso import GroupLasso\n",
    "from sklearn.utils import resample, check_random_state\n",
    "from sklearn.model_selection import cross_val_score, cross_validate, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential, Input, regularizers\n",
    "from tensorflow.keras.layers import Dense, LSTM, GRU, SimpleRNN, Dropout\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_probability as tfp\n",
    "from tensorflow.keras import layers\n",
    "from kerastuner.tuners import RandomSearch, BayesianOptimization\n",
    "from kerastuner.engine.hyperparameters import HyperParameters\n",
    "import time\n",
    "import pickle\n",
    "import os\n",
    "from numpy.random import seed\n",
    "import lime\n",
    "import lime.lime_tabular\n",
    "seed(1)\n",
    "\n",
    "from extra_functions import *\n",
    "\n",
    "# Silence some warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T14:48:56.358461Z",
     "iopub.status.busy": "2021-02-09T14:48:56.357998Z",
     "iopub.status.idle": "2021-02-09T14:49:04.818353Z",
     "shell.execute_reply": "2021-02-09T14:49:04.818809Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('energydata_complete.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df.set_index('date')\n",
    "\n",
    "fig = plot_data(df)\n",
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating extra features to describe time\n",
    "weekday: number [0,6]\\\n",
    "weekstatus: binary describing weekend (1) or not (0)\\\n",
    "NSM: Number of Seconds from Midnight\n",
    "\n",
    "These are used for filtering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T14:49:04.852017Z",
     "iopub.status.busy": "2021-02-09T14:49:04.851538Z",
     "iopub.status.idle": "2021-02-09T14:49:04.853614Z",
     "shell.execute_reply": "2021-02-09T14:49:04.854001Z"
    }
   },
   "outputs": [],
   "source": [
    "weekday = np.zeros(len(df))\n",
    "weekstatus = np.zeros(len(df))\n",
    "NSM = np.zeros(len(df))\n",
    "month = np.zeros(len(df))\n",
    "\n",
    "for i, val in enumerate(df.index):\n",
    "    weekday[i] = val.weekday()\n",
    "    weekstatus[i] = (weekday[i] >= 5)  # False for workday, True for weekend\n",
    "    NSM[i] = (val - val.replace(hour=0, minute=0, second=0, microsecond=0)).total_seconds()\n",
    "    month[i] = val.month\n",
    "\n",
    "df['weekday'] = weekday\n",
    "#df['week status'] = weekstatus\n",
    "df['NSM'] = NSM\n",
    "df['month'] = month\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add n previous timepoints to the data\n",
    "\n",
    "Here we add the result vector from \"t-n\" as part of the covariates. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = [1, 6, 144] # Make a list in-case we want to skip some \"n\"\n",
    "y = df['Appliances'].values # get y\n",
    "for n in ns:\n",
    "    temp = np.zeros_like(y)\n",
    "    temp[n:] = y[:-n]\n",
    "    df[f\"t-{n}\"]=temp\n",
    "# Strip the first max(n) datapoints that now miss data\n",
    "n = max(ns)\n",
    "df = df[n:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T14:49:04.860842Z",
     "iopub.status.busy": "2021-02-09T14:49:04.859591Z",
     "iopub.status.idle": "2021-02-09T14:49:04.988072Z",
     "shell.execute_reply": "2021-02-09T14:49:04.987599Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "\n",
    "# These two plots should be identical\n",
    "plt.plot(df['t-1'][:10],df['Appliances'][:10], lw=3, label=\"real\")\n",
    "plt.plot(df['t-1'][:10], df['t-1'][1:11], label=\"shifted t-1\") \n",
    "plt.xlabel('t-1')\n",
    "plt.ylabel('Appliances')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering data and making training/validation/test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T14:49:04.992536Z",
     "iopub.status.busy": "2021-02-09T14:49:04.992044Z",
     "iopub.status.idle": "2021-02-09T14:49:04.997415Z",
     "shell.execute_reply": "2021-02-09T14:49:04.997822Z"
    }
   },
   "outputs": [],
   "source": [
    "indices = (np.in1d(df.index.month, (1,2)))\n",
    "\n",
    "# Train/validation/test\n",
    "df_train = df[indices]\n",
    "df_valid = df[(df.index.month==3)]\n",
    "df_test = df[(df.index.month==4)]\n",
    "\n",
    "X_train = np.array(df_train[df.columns[df.columns!='Appliances']])\n",
    "y_train = np.array(df_train[df.columns[df.columns=='Appliances']])\n",
    "X_test = np.array(df_test[df.columns[df.columns!='Appliances']])\n",
    "y_test = np.array(df_test[df.columns[df.columns=='Appliances']])\n",
    "X_valid = np.array(df_valid[df.columns[df.columns!='Appliances']])\n",
    "y_valid = np.array(df_valid[df.columns[df.columns=='Appliances']])\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler().fit(X_train)\n",
    "X_train = scaler.transform(X_train)\n",
    "scaler = StandardScaler().fit(X_valid)\n",
    "X_valid = scaler.transform(X_valid)\n",
    "scaler = StandardScaler().fit(X_test)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "y_test_mean = y_test.mean()\n",
    "y_valid_mean = y_valid.mean()\n",
    "y_train_mean = y_train.mean()\n",
    "\n",
    "y_train = y_train - y_train_mean\n",
    "y_valid = y_valid - y_valid_mean\n",
    "y_test = y_test - y_test_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that the filter was correct\n",
    "print(len(df[(df.index.month==1)])+ len(df[(df.index.month==2)]))\n",
    "print(len(df_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correlations of covariates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T14:49:05.005598Z",
     "iopub.status.busy": "2021-02-09T14:49:05.001748Z",
     "iopub.status.idle": "2021-02-09T14:49:05.614325Z",
     "shell.execute_reply": "2021-02-09T14:49:05.613576Z"
    }
   },
   "outputs": [],
   "source": [
    "cor = df_train[df_train.columns].corr()\n",
    "fig, ax = plt.subplots(figsize=(10,10)) \n",
    "sns.heatmap(cor, square=True, xticklabels=True, yticklabels=True, cmap='RdBu')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Networks\n",
    "\n",
    "### Feedforward Neural Network\n",
    "The first neural network is actually not a RNN, but a feedforward network, where we include the input features t-n, which denotes the response variable from earlier time steps.\n",
    "\n",
    "The network architecture consists of a number of dense layers each followed by a dropout layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyper parameter tuning\n",
    "\n",
    "Hyperparameter tuning of a NN model using either Random Search or Bayesian optimization:\n",
    "\n",
    "The hyperparameters are:\n",
    "\n",
    "1. Input layer size\n",
    "2. Number of layers\n",
    "3. Size of each layer\n",
    "4. Regularization term (same for each layer)\n",
    "5. Learning rate\n",
    "6. Learning rate decay\n",
    "\n",
    "The maximum values, minimum values and step size are chosen below in the method ```build_model```\n",
    "\n",
    "\n",
    "# Next step might take a long time to run!!!\n",
    "\n",
    "When ```trials = 1000``` the next step took 2 hours and 22 minutes to run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Building NN and yuning hyper parameters\n",
    "\n",
    "# Number of different models tried in the tuning process\n",
    "trials = 2000\n",
    "trials = 10\n",
    "# Number of initial randomly selected points in the tuning process\n",
    "starting_points = 200\n",
    "\n",
    "# Early stopping\n",
    "es = EarlyStopping(monitor=\"val_loss\",patience=5)\n",
    "\n",
    "# Timer\n",
    "LOG_DIR = f\"{int(time.time())}\"\n",
    "\n",
    "def build_model(hp):\n",
    "    \n",
    "    # Model\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Building layers\n",
    "    for i in range(hp.Int('n_layers',min_value=1,max_value=3)):\n",
    "        model.add(Dense(hp.Int(f\"units_{i+1}\",min_value=50,max_value=1000,step=50), \n",
    "             activation='relu', \n",
    "             name=f\"dense{i+1}\",\n",
    "             kernel_regularizer=regularizers.l2(hp.Float('l2',1e-6,1)),           \n",
    "            )\n",
    "        )\n",
    "        model.add(Dropout(hp.Float(f\"drop_out_rate\",0,0.9,0.1),\n",
    "                         name=f\"dropout{i+1}\"))\n",
    "    \n",
    "    \n",
    "    model.add(Dense(1,activation='linear', name=\"outputlayer\"))\n",
    "\n",
    "    # ADAM optimizer, learning rate and decay is specified\n",
    "    opt = tf.keras.optimizers.Adam(lr=hp.Float('lr',1e-4,1e-3), decay=hp.Float('decay',1e-6,1e-5))\n",
    "\n",
    "    # The NN is compiled. A MSE loss function is used.\n",
    "    model.compile(loss='mse',\n",
    "           optimizer=opt,\n",
    "           metrics='mse',\n",
    "           )\n",
    "    \n",
    "    return model\n",
    "\n",
    "## Tuner object\n",
    "# tuner = RandomSearch(build_model,\n",
    "#                      objective = 'val_mse',\n",
    "#                      max_trials = trials,\n",
    "#                      executions_per_trial = 1,\n",
    "#                      directory = LOG_DIR\n",
    "#                     )\n",
    "\n",
    "tuner = BayesianOptimization(build_model,\n",
    "                     objective = 'val_mse',\n",
    "                     max_trials = trials,\n",
    "                     executions_per_trial = 1,\n",
    "                     seed = 123,\n",
    "                     num_initial_points = starting_points,\n",
    "                     alpha = 1e-4,  # 1e-4 by default\n",
    "                     beta = 1,   # 2.6 by default. I don't think we want to explore much and rather find a local min\n",
    "                     directory = LOG_DIR\n",
    "                    )\n",
    "\n",
    "# Tuner search\n",
    "tuner.search(x=X_train,\n",
    "             y=y_train,\n",
    "             epochs = 3,\n",
    "             validation_data=(X_valid,y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best selection of hyperparameters found from tuning\n",
    "best_hp = tuner.get_best_hyperparameters()[0]\n",
    "hp_folder = \"best_hyper_params\"\n",
    "if not os.path.exists(hp_folder):\n",
    "    os.mkdir(hp_folder)\n",
    "filename = f\"{hp_folder}/NN_hp_{trials}trials_{starting_points}init.pckl\"\n",
    "pickle.dump(best_hp, open(filename, 'wb'))\n",
    "best_hp.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiling the model using the best params\n",
    "model = build_model(best_hp)\n",
    "\n",
    "# The model is fitted to the training data and validated using the validation data. Variable number of epochs.\n",
    "history = model.fit(X_train,y_train, epochs=20, verbose=0, validation_data=(X_valid,y_valid), callbacks=es)\n",
    "\n",
    "# The predicted values are found using the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.plot(np.arange(1,len(history.history['mse'])+1),history.history['mse'],'k-',label='Train')\n",
    "plt.plot(np.arange(1,len(history.history['mse'])+1),history.history['val_mse'],'b-',label='Validation')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Mean squared error')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A summary of the used network\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function that calculates the R^2 value\n",
    "def coeff_determination(y_true, y_pred):\n",
    "    SS_res =  np.sum(( y_true - y_pred )**2)\n",
    "    SS_tot = np.sum(( y_true - np.mean(y_true) )**2 )\n",
    "    return ( 1 - SS_res/SS_tot )\n",
    "\n",
    "# Train and test score given by R^2\n",
    "print('Train score: '+ str(coeff_determination(y_train,model.predict(X_train))))\n",
    "print('Test score: '+ str(coeff_determination(y_test,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A plot of real data and predicted data in time between two time intervals:\n",
    "\n",
    "index_first = 1000\n",
    "index_last = 1600\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(df_test.index[index_first:index_last],y_test[index_first:index_last]+y_test_mean,'k-', label='True')\n",
    "plt.plot(df_test.index[index_first:index_last],y_pred[index_first:index_last]+y_test_mean,'r-', label='Predicted')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Appliances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A plot of real data and predicted data in time between two time intervals:\n",
    "\n",
    "index_first = 1100\n",
    "index_last = 1110\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(df_test.index[index_first:index_last],y_test[index_first:index_last]+y_test_mean,'k-', label='True')\n",
    "plt.plot(df_test.index[index_first:index_last],y_pred[index_first:index_last]+y_test_mean,'r-', label='Predicted')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Appliances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,8))\n",
    "plt.plot(y_pred,y_test,'b.')\n",
    "plt.plot([-100,900],[-100,900],'k-')\n",
    "plt.grid()\n",
    "plt.xlabel('Predicted Appliances')\n",
    "plt.ylabel('True Appliances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lime explaination of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add a predictor function that adds the y_test_mean\n",
    "def predictor(*args, **kwargs):\n",
    "    return model.predict(*args, **kwargs)+y_test_mean\n",
    "\n",
    "explainer = lime.lime_tabular.LimeTabularExplainer(X_train, feature_names=df.columns[df.columns!='Appliances'], \n",
    "                                                   class_names=['Appliances'],\n",
    "                                                   categorical_features=['weekday'],\n",
    "                                                   verbose=True, mode='regression')\n",
    "# Pick a high consumption point\n",
    "i = 1101\n",
    "exp = explainer.explain_instance(X_test[i], predictor, num_features=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick a average/low consumption point\n",
    "i = 100\n",
    "exp = explainer.explain_instance(X_test[i], predictor, num_features=10)\n",
    "exp.show_in_notebook(show_table=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp.as_list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision tree surrogacy\n",
    "\n",
    "Here we are going to investigate what the most important feature is in the trained neural net by training a surrugate model on the output of the NN model. Then we investigate the tree to figure out what features are most important for the NN predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T14:49:10.115111Z",
     "iopub.status.busy": "2021-02-09T14:49:10.114442Z",
     "iopub.status.idle": "2021-02-09T14:49:10.117154Z",
     "shell.execute_reply": "2021-02-09T14:49:10.116723Z"
    }
   },
   "outputs": [],
   "source": [
    "# Sander's code here\n",
    "\n",
    "# Retrain the model\n",
    "# Compiling the model using the best params\n",
    "model = build_model(best_hp)\n",
    "\n",
    "# The model is fitted to the training data and validated using the validation data. Variable number of epochs.\n",
    "_ = model.fit(X_train,y_train, epochs=20, verbose=0, validation_data=(X_valid,y_valid), callbacks=es)\n",
    "\n",
    "\n",
    "# Set X train to original, but replace Y to the response of the network\n",
    "s_X_train = X_train\n",
    "s_Y_train = model.predict(X_train)\n",
    "\n",
    "s_X_test = X_test\n",
    "s_Y_test = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeRegressor(random_state=42)\n",
    "clf.fit(s_X_train, s_Y_train)\n",
    "y_hat_train = clf.predict(s_X_train)\n",
    "y_hat_test = clf.predict(s_X_test)\n",
    "train_err = np.average(np.sqrt((y_hat_train-s_Y_train)**2))\n",
    "test_err = np.average(np.sqrt((y_hat_test-s_Y_test)**2))\n",
    "print(f\"Train MSE: {train_err}\")\n",
    "print(f\"Test MSE: {test_err}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Train score: {coeff_determination(s_Y_train, y_hat_train)}\")\n",
    "print(f\"Train score: {coeff_determination(s_Y_test, y_hat_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A plot of real data and predicted data in time between two time intervals:\n",
    "\n",
    "index_first = 1000\n",
    "index_last = 1600\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(df_test.index[index_first:index_last],s_Y_test[index_first:index_last]+y_test_mean,'r-', label='NN Predicted')\n",
    "plt.plot(df_test.index[index_first:index_last],y_hat_test[index_first:index_last]+y_test_mean,'b-', label='surrogate Predicted')\n",
    "plt.plot(df_test.index[index_first:index_last],y_test[index_first:index_last]+y_test_mean,'k-', label='True')\n",
    "\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Appliances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we print the features in order of imporance\n",
    "feature_importances = clf.tree_.compute_feature_importances()\n",
    "idx = np.argsort(feature_importances)[::-1]\n",
    "keys = df.keys()[1:]\n",
    "for i in idx:\n",
    "    print(f\"{keys[i]}: {feature_importances[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-09T14:49:08.802743Z",
     "iopub.status.busy": "2021-02-09T14:49:08.802250Z",
     "iopub.status.idle": "2021-02-09T14:49:09.362496Z",
     "shell.execute_reply": "2021-02-09T14:49:09.361497Z"
    }
   },
   "outputs": [],
   "source": [
    "# Youngrong's code her\n",
    "\n",
    "## A randomforest model is made. All the ranges of the parameters used for the model are specified.\n",
    "## Hyperparameters are tunned by gridsearchCV on validation data(Month==3)\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "\n",
    "# Range of the gridsearch for RF hyperparameters\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [5, 10, 20],\n",
    "    'max_features': ['auto','sqrt'],\n",
    "    'min_samples_leaf': [1, 2],\n",
    "    'min_samples_split': [2, 5],\n",
    "    'n_estimators': [100, 300, 500, 1000]\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_search = GridSearchCV(estimator=model, param_grid=param_grid,\n",
    "                               cv=3, n_jobs=-1, verbose=2)\n",
    "\n",
    "# Validation with the data to find the best set of hyperparameters\n",
    "grid_search.fit(X_valid,y_valid.ravel())\n",
    "\n",
    "# A summary of the chosen pararmeters\n",
    "print(grid_search.best_params_)\n",
    "\n",
    "# The model is fitted to the training data and validated using the validation data.\n",
    "rf = model.set_params(**grid_search.best_params_)\n",
    "\n",
    "rf.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_search = RandomizedSearchCV(estimator = model, param_distributions = param_grid, n_iter = 100, cv = 3, verbose=2, random_state=1, n_jobs = -1)\n",
    "\n",
    "# Validation with the data to find the best set of hyperparameters\n",
    "random_search.fit(X_valid,y_valid.ravel())\n",
    "\n",
    "# A summary of the chosen pararmeters\n",
    "print('Best parameter:' +str(random_search.best_params_))\n",
    "\n",
    "# The model is fitted to the training data and validated using the validation data.\n",
    "rf = model.set_params(**random_search.best_params_)\n",
    "\n",
    "rf.fit(X_train, y_train.ravel())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the RF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model to disk\n",
    "filename = 'RF_model.sav'\n",
    "pickle.dump(rf, open(filename, 'wb'))\n",
    "# load the model from disk\n",
    "#rf = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The predicted values are found using the test data\n",
    "y_pred = rf.predict(X_test)\n",
    "\n",
    "print('Train score: '+ str(coeff_determination(y_train.ravel(),rf.predict(X_train))))\n",
    "print('Test score: '+ str(coeff_determination(y_test.ravel(),y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A plot of real data and predicted data in time between two time intervals:\n",
    "\n",
    "index_first = 500\n",
    "index_last = 1000\n",
    "\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(df_test.index[index_first:index_last],y_test[index_first:index_last],'k-', label='True')\n",
    "plt.plot(df_test.index[index_first:index_last],y_pred[index_first:index_last],'r-', label='Predicted')\n",
    "plt.legend()\n",
    "plt.grid()\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Appliances')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(y_pred,y_test,'b.')\n",
    "plt.plot([0,1000],[0,1000],'k-')\n",
    "plt.grid()\n",
    "plt.xlabel('Predicted Appliances')\n",
    "plt.ylabel('True Appliances')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
